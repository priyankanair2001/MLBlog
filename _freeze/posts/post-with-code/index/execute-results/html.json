{
  "hash": "2d604e07c0f3d782bf1180235362a586",
  "result": {
    "markdown": "---\ntitle: \"Precision-Recall Curves\"\nauthor: \"Priyanka Nair\"\ndate: \"2023-11-13\"\ncategories: [Classification]\n---\n\nHello! In this blog post, I will be teaching you about precision-recall curves. A precision-recall curve can help us measure the quality of our model. So you may be wondering... what exactly are precision and recall?\n\nPrecision: true positives / all positives\n\nRemember, all positives are true positives + false positives\n\nRecall: true positives / (true positives + false negatives)\n\nSo, you can think of precision as measuring how many selected items were relevant, and recall as how many relevant items are selected.\n\nPrecision and recall trade off. Increased precision leads to decreased recall and increased recall leads to decreased precision.\n\nNow, I will explain something really important: how do we read a graph with a precision-recall curve?\n\nBasically, we want both precision and recall to be as high as possible. Since precision is on the y-axis and recall is on the x-axis, the higher the points are on the graph, the more precision they indicate, and the farther right the points are, the more recall they indicate. Therefore, we want our curve to be as close to the top right corner of the graph as possible. As a result, the area under the curve should also be as high as possible.\n\nTo illustrate how precision-recall curves are used, I will provide an example.\n\nA precision-recall curve can be very useful in the real world, especially in the medical field for detecting illnesses such as breast cancer. Here, we will use sklearn's breast cancer dataset, where a tumor will be classified as either malignant (1) or benign (0). As usual, our PR-curve will show us how good our model is.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve, auc\n\n# Load the Breast Cancer dataset\ncancer = load_breast_cancer()\nX = cancer.data\ny = cancer.target  # 1 if malignant, 0 if benign\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a logistic regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict probabilities on the test set\ny_scores = model.predict_proba(X_test)[:, 1]\n\n# Calculate precision and recall\nprecision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n\n# Calculate the area under the precision-recall curve\nauc_score = auc(recall, precision)\n\n# Plot the precision-recall curve\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, color='purple', label=f'PR Curve (AUC = {auc_score:.2f})')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for Breast Cancer Classification')\nplt.legend()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){width=672 height=523}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}